{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pritam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv # For loading environment variables\n",
    "import os # For accessing environment variables\n",
    "import openai # For interacting with OpenAI's API\n",
    "import langchain # LangChain for chaining LLMs with vector stores and other integrations\n",
    "import tiktoken # For text tokenization and counting, especially with OpenAI embeddings\n",
    "# For PDF parsing (PyMuPDF)\n",
    "import fitz  # PyMuPDF is imported as fitz\n",
    "from pinecone import Pinecone, ServerlessSpec # For Pinecone vector database (newer Pinecone client usage)\n",
    "## If building a web server or API (optional)\n",
    "import requests\n",
    "# import fastapi\n",
    "# import uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path='./.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking env 1\n",
    "load_dotenv(override=True) # Overwrite existing environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pritam\\Desktop\\ML projects\\LLM Q\n",
      "OPENAI_API_KEY: sk-proj-**************************************\n",
      "PINECONE_API_KEY: pcsk_2******************************\n",
      "PINECONE_ENV: us-east-1-aws\n",
      "PINECONE_INDEX_NAME: my-index\n",
      "PINECONE_PROJECT_NAME: insightxpc\n"
     ]
    }
   ],
   "source": [
    "#checking env 2                                                   \n",
    "load_dotenv()  # Ensure .env is in this directory\n",
    "print(os.getcwd())  # Check current directory\n",
    "print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"PINECONE_API_KEY:\", os.getenv(\"PINECONE_API_KEY\"))\n",
    "print(\"PINECONE_ENV:\", os.getenv(\"PINECONE_ENV\"))\n",
    "print(\"PINECONE_INDEX_NAME:\", os.getenv(\"PINECONE_INDEX_NAME\"))\n",
    "print(\"PINECONE_PROJECT_NAME:\", os.getenv(\"PINECONE_PROJECT_NAME\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pc = Pinecone(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    project_name=os.getenv(\"PINECONE_PROJECT_NAME\")  # Add if needed\n",
    ")\n",
    "\n",
    "indexes = pc.list_indexes().indexes\n",
    "existing_index_names = [idx.name for idx in indexes]\n",
    "\n",
    "if 'my-index' not in existing_index_names:\n",
    "    pc.create_index(\n",
    "        name='my-index',\n",
    "        dimension=1536,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 95832 characters from the PDF.\n"
     ]
    }
   ],
   "source": [
    "#Simple_chunking\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf):\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Extract text \n",
    "pdf_path = \"budget_speech.pdf\" \n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(f\"Extracted {len(pdf_text)} characters from the PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 138\n",
      "Sample metadata for the first chunk: {'chunk': 1, 'source': 'budget_speech.pdf', 'page': 6}\n"
     ]
    }
   ],
   "source": [
    "#Extracting Text and Metadata\n",
    "import fitz  # PyMuPDF\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def extract_text_with_metadata(pdf_path):\n",
    "    \"\"\"Extract text from a PDF along with page-level metadata.\"\"\"\n",
    "    chunks = []\n",
    "    metadata_list = []\n",
    "\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf, start=1):\n",
    "            page_text = page.get_text()\n",
    "\n",
    "            # Chunk the page text\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=1000,  # Chunk size in characters\n",
    "                chunk_overlap=200,  # Overlap for context preservation\n",
    "                separators=[\"\\n\\n\", \"\\n\", \" \"]  # Split at logical boundaries\n",
    "            )\n",
    "            page_chunks = text_splitter.split_text(page_text)\n",
    "\n",
    "            # Adding chunk along with metadata\n",
    "            for i, chunk in enumerate(page_chunks):\n",
    "                chunks.append(chunk)\n",
    "                metadata_list.append({\n",
    "                    \"chunk\": i,\n",
    "                    \"source\": \"budget_speech.pdf\",\n",
    "                    \"page\": page_num\n",
    "                })\n",
    "\n",
    "    return chunks, metadata_list\n",
    "\n",
    "# Path to PDF\n",
    "pdf_path = \"budget_speech.pdf\"\n",
    "\n",
    "# Extract text chunks and metadata from the target PDF\n",
    "chunks, metadata_list = extract_text_with_metadata(pdf_path)\n",
    "\n",
    "print(f\"Number of chunks created: {len(chunks)}\")\n",
    "print(\"Sample metadata for the first chunk:\", metadata_list[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"name\": \"my-index\",\n",
      "    \"dimension\": 1536,\n",
      "    \"metric\": \"cosine\",\n",
      "    \"host\": \"my-index-dczve5j.svc.aped-4627-b74a.pinecone.io\",\n",
      "    \"spec\": {\n",
      "        \"serverless\": {\n",
      "            \"cloud\": \"aws\",\n",
      "            \"region\": \"us-east-1\"\n",
      "        }\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"ready\": true,\n",
      "        \"state\": \"Ready\"\n",
      "    },\n",
      "    \"deletion_protection\": \"disabled\"\n",
      "}, {\n",
      "    \"name\": \"quickstart\",\n",
      "    \"dimension\": 1536,\n",
      "    \"metric\": \"cosine\",\n",
      "    \"host\": \"quickstart-dczve5j.svc.aped-4627-b74a.pinecone.io\",\n",
      "    \"spec\": {\n",
      "        \"serverless\": {\n",
      "            \"cloud\": \"aws\",\n",
      "            \"region\": \"us-east-1\"\n",
      "        }\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"ready\": true,\n",
      "        \"state\": \"Ready\"\n",
      "    },\n",
      "    \"deletion_protection\": \"disabled\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "# checking 4 indexes in pinecone \n",
    "print(pc.list_indexes().indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pritam\\AppData\\Local\\Temp\\ipykernel_15204\\403520706.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings # For OpenAI embedding\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "chunk_embeddings = embeddings.embed_documents(chunks) # Embedding the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "environment = os.getenv(\"PINECONE_ENV\") or \"us-east-1-aws\"\n",
    "index_name = os.getenv(\"PINECONE_INDEX_NAME\") or \"my_index\"\n",
    "\n",
    "# Initialize Pinecone instance\n",
    "pc = Pinecone(\n",
    "    api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List existing indexes\n",
    "existing_indexes = pc.list_indexes().indexes\n",
    "existing_index_names = [idx.name for idx in existing_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pritam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINECONE_API_KEY: pcsk_2******************************\n",
      "PINECONE_PROJECT_NAME: insightxpc\n",
      "Error initializing Pinecone: (401)\n",
      "Reason: Unauthorized\n",
      "HTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '5c9e28844c8af896b347e1e2963880cd', 'Date': 'Sat, 07 Dec 2024 12:08:56 GMT', 'Content-Type': 'text/html', 'Server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
      "HTTP response body: Invalid API Key\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Print out environment variables to verify\n",
    "print(\"PINECONE_API_KEY:\", os.getenv(\"PINECONE_API_KEY\"))\n",
    "print(\"PINECONE_PROJECT_NAME:\", os.getenv(\"PINECONE_PROJECT_NAME\"))\n",
    "\n",
    "# Updated Pinecone initialization\n",
    "try:\n",
    "    pc = Pinecone(\n",
    "        api_key=os.getenv(\"PINECONE_API_KEY\")\n",
    "        # Remove project_name if not explicitly required\n",
    "    )\n",
    "    \n",
    "    # Verify index creation or connection\n",
    "    indexes = pc.list_indexes()\n",
    "    print(\"Existing indexes:\", indexes)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Pinecone: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY= \"*********************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my-index', 'quickstart']\n",
      "Index 'quickstart' accessed successfully!\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    project_name=os.getenv(\"PINECONE_PROJECT_NAME\")\n",
    ")\n",
    "\n",
    "# List all indexes to check if \"quickstart\" exists\n",
    "print(pc.list_indexes().names())  # If \"quickstart\" isn't listed, create it.\n",
    "\n",
    "# Create the index if it doesn't exist\n",
    "if \"quickstart\" not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=\"quickstart\",\n",
    "        dimension=1536,  # the dimension of embeddings \n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# accessing the index\n",
    "index = pc.Index(\"quickstart\")\n",
    "print(\"Index 'quickstart' accessed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted 138 chunks to Pinecone index\n"
     ]
    }
   ],
   "source": [
    "# Upsert chunks to Pinecone index\n",
    "for i, (chunk, embedding, metadata) in enumerate(zip(chunks, chunk_embeddings, metadata_list)):\n",
    "    unique_id = f\"chunk_{i}\"\n",
    "    try:\n",
    "        index.upsert(\n",
    "            vectors=[(unique_id, embedding, {\"text\": chunk, **metadata})]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error upserting chunk {i}: {e}\")\n",
    "\n",
    "print(f\"Upserted {len(chunks)} chunks to Pinecone index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import openai\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def retrieve_relevant_chunks(query, top_k=3):\n",
    "    # Generate query embedding\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    \n",
    "    # Search Pinecone index\n",
    "    results = index.query(\n",
    "        vector=query_embedding, \n",
    "        top_k=top_k, \n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    return results['matches']\n",
    "\n",
    "def generate_answer(query, relevant_chunks):\n",
    "    # Combine retrieved chunks into context\n",
    "    context = \"\\n\\n\".join([\n",
    "        chunk['metadata'].get('text', '') for chunk in relevant_chunks\n",
    "    ])\n",
    "    \n",
    "    # Prepare prompt\n",
    "    prompt = f\"\"\"\n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Based on the provided context from the budget speech, provide a comprehensive and precise answer.\n",
    "    If the information is not in the context, state that you cannot find relevant information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate response using OpenAI\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on given context.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def answer_question(query):\n",
    "    # Retrieve relevant chunks\n",
    "    relevant_chunks = retrieve_relevant_chunks(query)\n",
    "    \n",
    "    # Generate answer\n",
    "    answer = generate_answer(query, relevant_chunks)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget Speech Q&A Assistant\n",
      "Ask questions about the budget speech. Type 'exit' to quit.\n",
      "Error processing your query: name 'answer_question' is not defined\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Budget Speech Q&A Assistant\")\n",
    "    print(\"Ask questions about the budget speech. Type 'exit' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        query = input(\"\\nYour question: \")\n",
    "        \n",
    "        # Check if user wants to exit\n",
    "        if query.lower() == 'exit':\n",
    "            print(\"Thank you for using the Budget Speech Assistant!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Get and print the answer\n",
    "            response = answer_question(query)\n",
    "            print(\"\\nAnswer:\", response)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing your query: {e}\")\n",
    "\n",
    "# Run the main interaction\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
